# GeneraciÃ³n AutomÃ¡tica de Algoritmos (GAA): GuÃ­a de Funcionamiento
## Con ejemplos de ejecuciÃ³n tipo

---

## âš ï¸ AclaraciÃ³n Importante

**En GAA-GCP-ILS-4**: NO hay generaciÃ³n automÃ¡tica de algoritmos.  
**En KBP-SA**: SÃ hay generaciÃ³n automÃ¡tica completa y funcional.

Este documento describe **cÃ³mo funciona en KBP-SA** como referencia para entender el concepto.

---

## ğŸ“ Arquitectura General del Sistema GAA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA GAA                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. GRAMMAR (GramÃ¡tica BNF)                                  â”‚
â”‚     â””â”€ Define terminales y no-terminales vÃ¡lidos             â”‚
â”‚     â””â”€ Especifica reglas de combinaciÃ³n                      â”‚
â”‚                                                               â”‚
â”‚  2. GENERATOR (Generador Aleatorio)                          â”‚
â”‚     â””â”€ Crea AST aleatorios respetando gramÃ¡tica             â”‚
â”‚     â””â”€ Control de profundidad y diversidad                  â”‚
â”‚                                                               â”‚
â”‚  3. AST NODES (Nodos del Ãrbol SintÃ¡ctico)                   â”‚
â”‚     â””â”€ Seq, If, While, For, Call                            â”‚
â”‚     â””â”€ GreedyConstruct, LocalSearch, Perturbation          â”‚
â”‚                                                               â”‚
â”‚  4. INTERPRETER (IntÃ©rprete/Ejecutor)                        â”‚
â”‚     â””â”€ Ejecuta algoritmo representado como AST              â”‚
â”‚     â””â”€ Mantiene estado (soluciÃ³n, mejor, estadÃ­sticas)     â”‚
â”‚                                                               â”‚
â”‚  5. METAHEURISTIC (SA, GP, ILS)                              â”‚
â”‚     â””â”€ Busca mejor algoritmo (AST) entre poblaciÃ³n          â”‚
â”‚     â””â”€ Operadores genÃ©ticos sobre AST                       â”‚
â”‚                                                               â”‚
â”‚  6. EVALUATOR (Evaluador Multi-Instancia)                    â”‚
â”‚     â””â”€ Ejecuta algoritmo en N instancias                    â”‚
â”‚     â””â”€ Calcula fitness como promedio de rendimiento        â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujo de EjecuciÃ³n Tipo

### Fase 1: InicializaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Cargar GramÃ¡tica                     â”‚
â”‚    â€¢ Terminales constructivos            â”‚
â”‚    â€¢ Terminales de mejora                â”‚
â”‚    â€¢ Terminales de perturbaciÃ³n          â”‚
â”‚    â€¢ LÃ­mites de profundidad              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Cargar Problemas de Entrenamiento    â”‚
â”‚    â€¢ Instancias pequeÃ±as (training/)    â”‚
â”‚    â€¢ Instancias medias (validation/)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Inicializar Generador y MetaheurÃ­sticaâ”‚
â”‚    â€¢ Seed aleatorio o fijo              â”‚
â”‚    â€¢ PoblaciÃ³n de algoritmos (AST)      â”‚
â”‚    â€¢ ParÃ¡metros de evoluciÃ³n            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fase 2: GeneraciÃ³n de Algoritmos (Primera PoblaciÃ³n)

```
GENERADOR CREA 5 ALGORITMOS ALEATORIOS:

Algoritmo 1: 
  â”Œâ”€ Seq
  â”‚  â”œâ”€ GreedyConstruct("GreedyByRatio")
  â”‚  â””â”€ While(IterBudget=100)
  â”‚     â””â”€ LocalSearch("FlipBestItem", "Improving")

Algoritmo 2:
  â”Œâ”€ Seq
  â”‚  â”œâ”€ GreedyConstruct("GreedyByWeight")
  â”‚  â”œâ”€ For(n=10)
  â”‚  â”‚  â””â”€ If(Prob=0.3)
  â”‚  â”‚     â”œâ”€ Call("FlipBestItem")
  â”‚  â”‚     â””â”€ Call("RandomFlip", args={k: 2})

Algoritmo 3:
  â”Œâ”€ ChooseBestOf(n_tries=5)
  â”‚  â””â”€ Seq
  â”‚     â”œâ”€ GreedyConstruct("GreedyByValue")
  â”‚     â””â”€ LocalSearch("TwoExchange", "BestImprovement")

... (Algoritmos 4 y 5)
```

### Fase 3: EvaluaciÃ³n de Algoritmos (Multi-Instancia)

```
PARA CADA ALGORITMO (j=1 a 5):
  fitness[j] = 0
  
  PARA CADA INSTANCIA DE ENTRENAMIENTO (i=1 a 20):
    â€¢ Crear intÃ©rprete nuevo
    â€¢ Ejecutar AST_j sobre instancia_i
    â€¢ Registrar valor de soluciÃ³n final
    
  fitness[j] = mean(valores de todas instancias)

RESULTADO:
  Algoritmo 1: fitness = 850.5 (promedio en 20 instancias)
  Algoritmo 2: fitness = 923.1 â† MEJOR
  Algoritmo 3: fitness = 785.2
  Algoritmo 4: fitness = 901.3
  Algoritmo 5: fitness = 812.7
```

### Fase 4: EvoluciÃ³n mediante MetaheurÃ­stica (Simulated Annealing)

```
TEMPERATURA INICIAL: T = 1000

GENERACIÃ“N 1:
  Estado actual: Algoritmo 2 (fitness=923.1)
  
  â€¢ Mutar: Cambiar un nodo del AST
    - Reemplazar GreedyByRatio con GreedyByWeight
    
  AST mutado:
    â”Œâ”€ Seq
    â”‚  â”œâ”€ GreedyConstruct("GreedyByWeight")  â† MUTADO
    â”‚  â””â”€ While(IterBudget=100)
    â”‚     â””â”€ LocalSearch("FlipBestItem", "Improving")
  
  â€¢ Evaluar: fitness_mutado = 931.2 (mejora âœ“)
  
  â€¢ Aceptar: SIEMPRE (mejora)
  
  Mejor hasta ahora: Algoritmo Mutado (931.2)

GENERACIÃ“N 2:
  Estado actual: Algoritmo Mutado
  
  â€¢ Mutar: Cambiar profundidad del bucle While
    - Cambiar IterBudget=100 a IterBudget=200
  
  â€¢ Evaluar: fitness_mutado2 = 928.5 (empeora âœ—)
  
  â€¢ Aceptar: CON PROBABILIDAD e^(Î”f/T)
    - Î”f = 928.5 - 931.2 = -2.7
    - P = e^(-2.7/1000) â‰ˆ 0.997 â† ACEPTA igual (casi)
  
GENERACIÃ“N 3:
  Estado actual: Algoritmo Mutado2
  
  â€¢ Mutar: Cambiar condicional
  
  â€¢ Evaluar: fitness_mutado3 = 920.1 (peor)
  
  â€¢ Aceptar: P = e^(-11.1/1000) â‰ˆ 0.989 â† RECHAZA
  
  Volver a estado anterior

... (generaciones 4 a N)

TEMPERATURA FINAL: T = 0.1

RESULTADO FINAL:
  Mejor algoritmo encontrado: Algoritmo Evolucionado
  Fitness final: 945.7 (mejora respecto al inicial 923.1)
```

---

## ğŸ’» Ejemplo Detallado de CÃ³digo

### 1. Crear Generador

```python
from gaa.grammar import Grammar
from gaa.generator import AlgorithmGenerator

# Crear gramÃ¡tica (carga terminales del problema)
grammar = Grammar(min_depth=2, max_depth=4)

# Crear generador
generator = AlgorithmGenerator(grammar=grammar, seed=42)

# Generar algoritmo aleatorio
algorithm_ast = generator.generate()

print("Algoritmo generado:")
print(algorithm_ast.to_pseudocode())

# Salida:
# SECUENCIA:
#   1. ConstrucciÃ³n: GreedyByRatio
#   2. MIENTRAS IterBudget < 100:
#        Mejora Local: FlipBestItem
#   3. SI Estancamiento > 10:
#        PerturbaciÃ³n: RandomFlip(k=2)
```

### 2. Ejecutar Algoritmo en Instancia

```python
from gaa.interpreter import ASTInterpreter
from core.problem import KnapsackProblem
from core.evaluation import KnapsackEvaluator

# Cargar problema
problem = KnapsackProblem.load_from_file("datasets/training/kbp_100_1.txt")

# Crear intÃ©rprete
interpreter = ASTInterpreter(problem=problem, seed=42)

# Ejecutar algoritmo (AST) sobre problema
best_solution = interpreter.execute(algorithm_ast)

print(f"SoluciÃ³n encontrada:")
print(f"  â€¢ Valor: {best_solution.value}")
print(f"  â€¢ Items: {best_solution.items_count}")
print(f"  â€¢ Peso total: {best_solution.total_weight}")
print(f"  â€¢ EstadÃ­sticas:")
print(f"    - Iteraciones: {interpreter.context.iterations}")
print(f"    - Evaluaciones: {interpreter.context.evaluations}")
print(f"    - Tiempo (s): {interpreter.context.get_elapsed_time():.2f}")
```

### 3. Evaluar en MÃºltiples Instancias

```python
from data.loader import DatasetLoader

# Cargar mÃºltiples instancias
loader = DatasetLoader("datasets/")
training_instances = loader.load_folder("training")  # 20 instancias

# FunciÃ³n de evaluaciÃ³n
def evaluate_algorithm(algorithm_ast, instances):
    """Calcula fitness como promedio de desempeÃ±o en instancias"""
    
    values = []
    
    for instance in instances:
        # Crear intÃ©rprete para cada instancia
        interpreter = ASTInterpreter(problem=instance)
        
        # Ejecutar algoritmo
        solution = interpreter.execute(algorithm_ast)
        
        # Registrar valor
        values.append(solution.value)
    
    # Fitness = promedio
    fitness = sum(values) / len(values)
    
    return fitness

# Evaluar nuestro algoritmo
fitness = evaluate_algorithm(algorithm_ast, training_instances)

print(f"Fitness del algoritmo: {fitness:.2f}")
print(f"  (promedio de {len(training_instances)} instancias)")
```

### 4. Evolucionar Algoritmo con Simulated Annealing

```python
from metaheuristic.sa_core import SimulatedAnnealing

# Crear metaheurÃ­stica
sa = SimulatedAnnealing(
    initial_temperature=1000,
    cooling_rate=0.95,
    max_iterations=100
)

# FunciÃ³n objetiva: evaluar algoritmo en instancias
def objective(algorithm_ast):
    return evaluate_algorithm(algorithm_ast, training_instances)

# Optimizar (buscar mejor algoritmo)
best_algorithm, best_fitness = sa.optimize(
    initial_solution=algorithm_ast,
    objective_function=objective,
    move_operator=lambda ast: mutate_ast(ast, grammar)
)

print(f"Mejor algoritmo encontrado:")
print(f"  â€¢ Fitness: {best_fitness:.2f}")
print(f"  PseudocÃ³digo:")
print(best_algorithm.to_pseudocode())
```

---

## ğŸ“Š EjecuciÃ³n Completa: Script `demo_complete.py`

```bash
$ python scripts/demo_complete.py
```

**Salida esperada:**

```
================================================================================
  DEMO 1: Carga de Instancias
================================================================================

âœ… Instancia cargada: kbp_100_1
   â€¢ n = 100 Ã­tems
   â€¢ capacity = 500
   â€¢ optimal = 1050

âœ… 20 instancias cargadas de training/

================================================================================
  DEMO 2: GeneraciÃ³n AutomÃ¡tica de Algoritmos (GAA)
================================================================================

ğŸŒ³ GramÃ¡tica GAA cargada:
   â€¢ Terminales constructivos: 4
   â€¢ Terminales de mejora: 5
   â€¢ Terminales de perturbaciÃ³n: 3
   â€¢ Total de terminales: 12

ğŸ² Generando 3 algoritmos aleatorios...

âœ… Algoritmo 1 generado
   PseudocÃ³digo:
   SECUENCIA:
     1. ConstrucciÃ³n: GreedyByRatio
     2. MIENTRAS IterBudget < 100:
          Mejora Local: FlipBestItem

âœ… Algoritmo 2 generado
   PseudocÃ³digo:
   SECUENCIA:
     1. ConstrucciÃ³n: GreedyByValue
     2. PARA i = 0 a 20:
          SI Prob(0.3):
            Llamada: TwoExchange
          SINO:
            Llamada: RandomFlip(k=2)

âœ… Algoritmo 3 generado
   PseudocÃ³digo:
   ChooseBestOf(n=5):
     1. ConstrucciÃ³n: GreedyByWeight
     2. MIENTRAS IterBudget < 500:
          Mejora Local: BestImproveAll

================================================================================
  DEMO 3: EvaluaciÃ³n de Algoritmos (Multi-Instancia)
================================================================================

ğŸ”¬ Evaluando 3 algoritmos en 20 instancias...

Algoritmo 1:
  Instancia 1 (kbp_100_1): 1025.0
  Instancia 2 (kbp_100_2): 1012.5
  Instancia 3 (kbp_100_3): 1018.2
  ...
  Instancia 20 (kbp_100_20): 1020.1
  
  âœ… Fitness: 1018.5 (promedio)
  âœ… Tiempo total: 45.3 segundos

Algoritmo 2:
  ...
  âœ… Fitness: 1035.2 (promedio) â† MEJOR
  âœ… Tiempo total: 52.1 segundos

Algoritmo 3:
  ...
  âœ… Fitness: 995.7 (promedio)
  âœ… Tiempo total: 38.9 segundos

================================================================================
  DEMO 4: EvoluciÃ³n con Simulated Annealing
================================================================================

ğŸ§¬ Ejecutando Simulated Annealing para optimizar algoritmos...

  GeneraciÃ³n 1 (T=1000.00):
    Mejor actual: Alg_2 (fitness=1035.2)
    MutaciÃ³n: Cambiar mejora a "BestImproveOne"
    Evaluado: fitness=1038.1 (mejora âœ“)
    Aceptado: SIEMPRE
    
    Mejor global: 1038.1

  GeneraciÃ³n 2 (T=950.00):
    Mejor actual: Alg_2_mut (fitness=1038.1)
    MutaciÃ³n: Cambiar IterBudget a 200
    Evaluado: fitness=1036.5 (empeora âœ—)
    Aceptado: P(0.991) âœ“
    
    Mejor global: 1038.1 (sin cambio)

  GeneraciÃ³n 3 (T=902.50):
    Mejor actual: Alg_2_mut2 (fitness=1036.5)
    MutaciÃ³n: Cambiar construcciÃ³n a "GreedyByWeight"
    Evaluado: fitness=1041.3 (mejora âœ“)
    Aceptado: SIEMPRE
    
    Mejor global: 1041.3 âœ¨

  ...

  GeneraciÃ³n 100 (T=0.10):
    Mejor actual: Alg_FINAL (fitness=1045.7)
    MutaciÃ³n: Cambiar parÃ¡metro
    Evaluado: fitness=1045.5 (empeora)
    Aceptado: P(0.001) âœ—
    
    Mejor global: 1045.7

ğŸ Simulated Annealing finalizado

  âœ… Mejor algoritmo encontrado: Alg_FINAL
  âœ… Fitness final: 1045.7
  âœ… Mejora respecto al inicial: 10.5 (1.0%)
  âœ… Tiempo total: 432.1 segundos

================================================================================
  DEMO 5: AnÃ¡lisis de Resultados
================================================================================

ğŸ“Š Algoritmo Evolucionado - AnÃ¡lisis Detallado

Estructura AST:
  Profundidad mÃ¡xima: 4
  Total nodos: 12
  Operadores: 5
  VÃ¡lido: âœ“

DesempeÃ±o en training:
  Promedio: 1045.7
  MÃ­nimo: 1041.2
  MÃ¡ximo: 1049.3
  DesviaciÃ³n estÃ¡ndar: 2.1

InformaciÃ³n detallada:
  Instancia 1: 1047.0
  Instancia 2: 1045.3
  Instancia 3: 1043.1
  ...
  Instancia 20: 1046.2

ConfiguraciÃ³n del algoritmo:
  ConstrucciÃ³n: GreedyByWeight
  Mejora 1: BestImproveAll (IterBudget=200)
  Mejora 2: TwoExchange (IterBudget=100)
  Condicional: SI Mejora ENTONCES Aceptar

PseudocÃ³digo legible:
  1. ConstrucciÃ³n inicial con GreedyByWeight
  2. MIENTRAS evaluaciones < 200:
       Aplicar BestImproveAll
       SI mejora: aceptar
       SINO: con prob 0.3 aceptar igual
  3. PARA i = 1 a 100:
       SI no hay mejora hace 10 iteraciones:
         PerturbaciÃ³n: RandomFlip(k=3)
       Mejora local: TwoExchange
```

---

## ğŸ”‘ Conceptos Clave

### Ãrbol SintÃ¡ctico Abstracto (AST)

Un algoritmo se representa como un Ã¡rbol de nodos:

```
Algorithm = Seq([
    GreedyConstruct("GreedyByRatio"),
    While(
        budget=IterBudget(100),
        body=Seq([
            LocalSearch("FlipBestItem"),
            If(
                condition="Improves",
                then_branch=Call("TwoExchange"),
                else_branch=Call("RandomFlip", k=2)
            )
        ])
    )
])
```

**Ventajas:**
- âœ… RepresentaciÃ³n formal y estructurada
- âœ… FÃ¡cil de manipular genÃ©ticamente (mutar/cruzar subÃ¡rboles)
- âœ… Ejecutable (intÃ©rprete convierte AST en acciones)
- âœ… Serializable (guardar/cargar algoritmos)

### GramÃ¡tica BNF

Define quÃ© AST son vÃ¡lidos:

```bnf
<Algorithm> ::= <Stmt>
<Stmt> ::= Seq(<Stmt>*)
          | While(<Budget>, <Stmt>)
          | For(n, <Stmt>)
          | If(<Cond>, <Stmt>, <Stmt>)
          | Call(<Op>, <Args>)

<Op> ::= GreedyByRatio | GreedyByValue | ... (13 terminales)
<Cond> ::= Improves | Feasible | Prob(p)
```

**Beneficio:** El generador respeta estas reglas, evitando AST invÃ¡lidos.

### Fitness Multi-Instancia

Un algoritmo se evalÃºa en VARIAS instancias de entrenamiento:

```
fitness = mean([ejecutar(algoritmo, instancia_i).valor 
               for instancia_i in training_set])
```

**Por quÃ©:** Mide generalizaciÃ³n del algoritmo, no solo desempeÃ±o en caso particular.

---

## âš™ï¸ CÃ³mo Implementarlo en GAA-GCP-ILS-4

Si quisieras agregar GAA a GAA-GCP-ILS-4, estos serÃ­an los pasos:

### Paso 1: Crear mÃ³dulo `gaa/`

```
gaa/
â”œâ”€â”€ __init__.py          # Exportar clases
â”œâ”€â”€ ast_nodes.py         # Nodos: Seq, If, While, Call, GreedyConstruct, etc.
â”œâ”€â”€ grammar.py           # Reglas BNF de ILS para GCP
â”œâ”€â”€ generator.py         # AlgorithmGenerator
â””â”€â”€ interpreter.py       # ASTInterpreter (ejecutor)
```

### Paso 2: Definir Terminales para GCP

```python
# Terminales constructivos
CONSTRUCTIVE_TERMINALS = [
    "GreedyDSATUR",
    "GreedyLF",
    "RandomSequential",
    "GreedySL"
]

# Terminales de mejora
IMPROVEMENT_TERMINALS = [
    "KempeChain",
    "OneVertexMove",
    "TabuCol",
    "SwapColors"
]

# Terminales de perturbaciÃ³n
PERTURBATION_TERMINALS = [
    "RandomRecolor",
    "PartialDestroy",
    "ColorClassMerge"
]
```

### Paso 3: GramÃ¡tica BNF para ILS-GCP

```bnf
<ILSAlgorithm> ::= <Construction> <LoopPhase>

<Construction> ::= Call(GreedyDSATUR | GreedyLF | RandomSequential)

<LoopPhase> ::= While(<IterBudget>, <IterationBody>)

<IterationBody> ::= Seq([<Improvement>, <Perturbation>])
                   | Seq([<Improvement>, If(Improves, <Perturbation>)])

<Improvement> ::= Call(KempeChain | OneVertexMove | TabuCol)

<Perturbation> ::= Call(RandomRecolor | PartialDestroy)
                   with args {intensity: 0.1-0.5}
```

### Paso 4: Script de ExperimentaciÃ³n

```python
# scripts/gaa_experiment.py

from gaa.grammar import Grammar
from gaa.generator import AlgorithmGenerator
from gaa.interpreter import ASTInterpreter
from data.loader import DatasetLoader
from metaheuristic.sa_core import SimulatedAnnealing

# Cargar problemas de entrenamiento
loader = DatasetLoader("datasets/")
training = loader.load_folder("training")  # PequeÃ±os para entrenar

# Crear generador
grammar = Grammar(min_depth=2, max_depth=4)
generator = AlgorithmGenerator(grammar=grammar, seed=42)

# Generar poblaciÃ³n inicial
population = [generator.generate() for _ in range(10)]

# Definir fitness
def evaluate(algorithm):
    fitness = 0
    for instance in training:
        interpreter = ASTInterpreter(instance)
        solution = interpreter.execute(algorithm)
        fitness += (instance.colors_known - solution.num_colors)  # gap
    return fitness / len(training)

# Evolucionar con SA
sa = SimulatedAnnealing(max_iterations=50)
best_algorithm, best_fitness = sa.optimize(
    population[0], 
    evaluate,
    mutation_operator=lambda x: mutate_ast(x)
)

# Testear en validaciÃ³n
validation = loader.load_folder("validation")
test_fitness = evaluate_on_set(best_algorithm, validation)

print(f"Mejor algoritmo encontrado: {best_fitness}")
print(f"DesempeÃ±o en validaciÃ³n: {test_fitness}")
```

---

## ğŸ“ˆ Ventajas de GAA

| Aspecto | Ventaja |
|--------|---------|
| **AutomatizaciÃ³n** | No necesitas diseÃ±ar manualmente cada algoritmo |
| **OptimizaciÃ³n** | Los algoritmos se adaptan al problema especÃ­fico |
| **GeneralizaciÃ³n** | Multi-instancia asegura desempeÃ±o en casos nuevos |
| **Reproducibilidad** | Algoritmos son cÃ³digo (AST) ejecutable |
| **Escalabilidad** | Puedes evolucionar gran poblaciÃ³n de algoritmos |
| **AnÃ¡lisis** | Entiendes quÃ© funciona mejor (estructura AST) |

---

## ğŸ¯ ConclusiÃ³n

**GAA es un metamodelo**: en lugar de evolucionar soluciones de un problema,
evolucionas **algoritmos completos** representados como Ã¡rboles sintÃ¡cticos.

La ejecuciÃ³n tipo:
1. Generar AST aleatorios
2. Evaluar cada uno en mÃºltiples instancias
3. Evolucionar usando metaheurÃ­stica (SA, GP, ILS)
4. Seleccionar mejor algoritmo despuÃ©s de N generaciones

**Resultado**: Un algoritmo automÃ¡ticamente optimizado y generalizable.

---

**Referencia**: ImplementaciÃ³n completa en `projects/KBP-SA/gaa/`
