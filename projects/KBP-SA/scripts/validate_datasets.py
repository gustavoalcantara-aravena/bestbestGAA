"""
Script de Validaci√≥n de Datasets - KBP-SA

Valida que todos los datasets est√©n en el formato correcto.
"""

import sys
from pathlib import Path
import yaml

# A√±adir ruta de scripts del framework
framework_scripts = Path(__file__).parent.parent.parent / "04-Generated" / "scripts"
sys.path.insert(0, str(framework_scripts))

from data_loader import DataLoader


def load_config() -> dict:
    """Carga la configuraci√≥n del proyecto"""
    config_path = Path(__file__).parent / "config.yaml"
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def validate_datasets():
    """Valida todos los datasets del proyecto"""
    print("=" * 70)
    print("  Validaci√≥n de Datasets - KBP-SA")
    print("=" * 70)
    print()
    
    project_dir = Path(__file__).parent
    
    # Validar subsets incluidos
    subsets = {
        'low_dimensional': 'datasets/low_dimensional',
        'large_scale': 'datasets/large_scale',
        'training': 'datasets/training',
        'validation': 'datasets/validation',
        'test': 'datasets/test'
    }
    
    all_valid = True
    total_instances = 0
    results = {}
    
    for subset_name, subset_path in subsets.items():
        full_path = project_dir / subset_path
        
        if not full_path.exists():
            print(f"\nüìÇ {subset_name.upper()}: No existe")
            continue
        
        print(f"\nüìÇ Validando {subset_name.upper()}...")
        print("-" * 70)
        
        loader = DataLoader(
            dataset_dir=full_path,
            problem_type='knapsack'
        )
        
        # Cargar instancias del directorio
        txt_files = list(full_path.glob('*.txt'))
        
        if not txt_files:
            print(f"  ‚ö†Ô∏è  No se encontraron archivos .txt en {subset_path}/")
            results[subset_name] = {'valid': 0, 'invalid': 0, 'total': 0}
            continue
        
        valid_count = 0
        invalid_count = 0
        
        for txt_file in txt_files:
            try:
                instance = loader._parse_file(txt_file)
                instance['filename'] = txt_file.name
                is_valid = loader.validate_instance(instance)
                
                if is_valid:
                    valid_count += 1
                    print(f"  ‚úÖ {txt_file.name}: V√ÅLIDO (n={instance['n']}, W={instance['capacity']})")
                else:
                    invalid_count += 1
                    print(f"  ‚ùå {txt_file.name}: INV√ÅLIDO")
                    all_valid = False
            except Exception as e:
                invalid_count += 1
                print(f"  ‚ùå {txt_file.name}: ERROR - {e}")
                all_valid = False
        
        subset_total = valid_count + invalid_count
        total_instances += subset_total
        results[subset_name] = {
            'valid': valid_count,
            'invalid': invalid_count,
            'total': subset_total
        }
        
        print(f"\n  Resumen {subset_name}: {valid_count} v√°lidas, {invalid_count} inv√°lidas")
    
    # Resumen final
    print("\n" + "=" * 70)
    print("  RESUMEN FINAL")
    print("=" * 70)
    
    for subset_name, stats in results.items():
        if stats['total'] > 0:
            status = "‚úÖ" if stats['invalid'] == 0 else "‚ö†Ô∏è"
            print(f"{status} {subset_name}: {stats['valid']}/{stats['total']} v√°lidas")
    
    print(f"\nüìä Total de instancias: {total_instances}")
    
    if all_valid and total_instances > 0:
        print("‚úÖ Todos los datasets son v√°lidos")
        
        # Mostrar distribuci√≥n
        low_dim = results.get('low_dimensional', {}).get('total', 0)
        large_sc = results.get('large_scale', {}).get('total', 0)
        
        if low_dim > 0 or large_sc > 0:
            print("\nüì¶ Datasets incluidos:")
            if low_dim > 0:
                print(f"  ‚Ä¢ Low-dimensional: {low_dim} instancias (n=4-23)")
            if large_sc > 0:
                print(f"  ‚Ä¢ Large-scale: {large_sc} instancias (n=100-10000)")
        
        return True
    elif total_instances == 0:
        print("‚ö†Ô∏è  No se encontraron datasets")
        print("\nOpciones:")
        print("  1. Usar instancias incluidas en low_dimensional/ y large_scale/")
        print("  2. Generar ejemplos: python generate_example_datasets.py")
        print("  3. A√±adir tus propios datasets en training/, validation/, test/")
        print("\nFormato esperado:")
        print("  optimal_value")
        print("  n W")
        print("  v_1 w_1")
        print("  v_2 w_2")
        print("  ...")
        return False
    else:
        print("‚ùå Hay datasets inv√°lidos")
        return False


if __name__ == "__main__":
    success = validate_datasets()
    sys.exit(0 if success else 1)
