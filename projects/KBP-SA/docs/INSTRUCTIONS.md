# Instrucciones de Ejecuci√≥n - KBP-SA

## üöÄ Inicio R√°pido

### 1. Verificar Instalaci√≥n

```powershell
# Instalar dependencias
pip install -r ../../requirements.txt

# Verificar framework
python ../../05-Automation/sync-engine.py --validate
```

### 2. Preparar Datasets

**Opci√≥n A: Generar datasets de ejemplo**
```powershell
python generate_example_datasets.py
```

**Opci√≥n B: Usar tus propios datasets**

Coloca archivos `.txt` en las carpetas correspondientes:
- `datasets/training/` - Instancias para entrenar el GAA
- `datasets/validation/` - Instancias para ajustar par√°metros
- `datasets/test/` - Instancias para evaluar el algoritmo final

**Formato del archivo:**
```
n W
v_1 w_1
v_2 w_2
...
v_n w_n
```

Ejemplo (`kp_n5_W50.txt`):
```
5 50
10 5
20 10
30 15
15 8
25 12
```

### 3. Validar Datasets

```powershell
python validate_datasets.py
```

Deber√≠as ver:
```
‚úÖ Todos los datasets son v√°lidos
```

### 4. Ejecutar Optimizaci√≥n

```powershell
python run.py
```

**Salida esperada:**
```
======================================================================
  GAA - Generaci√≥n Autom√°tica de Algoritmos
  Proyecto: KBP-SA (Knapsack + Simulated Annealing)
======================================================================

üìä Cargando datasets...
‚úÖ Cargadas 3 instancias de training

üéØ Configurando problema...
‚öñÔ∏è  Configurando evaluador de fitness...
üî• Configurando Simulated Annealing...

======================================================================
  INICIANDO OPTIMIZACI√ìN
======================================================================

üî• Simulated Annealing iniciado (T0=100.0, Œ±=0.95)
  Eval 1000/10000 | T=0.5987 | Best=245.3421
  Eval 2000/10000 | T=0.3584 | Best=267.8934
  ...
```

### 5. Ver Resultados

Los resultados se guardan en `generated/results/`:
- `best_algorithm_YYYYMMDD_HHMMSS.txt` - AST del mejor algoritmo
- `history_YYYYMMDD_HHMMSS.json` - Historial de fitness

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Modificar Par√°metros de SA

Edita `config.yaml`:

```yaml
metaheuristic:
  parameters:
    T0: 150.0              # ‚Üë Mayor exploraci√≥n inicial
    alpha: 0.98            # ‚Üë Enfriamiento m√°s lento
    iterations_per_temp: 150
    max_evaluations: 20000 # ‚Üë M√°s evaluaciones
```

### Cambiar Terminales Disponibles

Edita `problema_metaheuristica.md` secci√≥n `Domain-Operators`:

```markdown
## Domain-Operators

### Constructivos
- **GreedyByValue**: ...
- **MiNuevoOperador**: Descripci√≥n [Autor2024]
```

Luego sincroniza:
```powershell
python ../../05-Automation/sync-engine.py --sync
```

---

## üìä An√°lisis de Resultados

### Leer el AST Generado

```python
# analyze_results.py
from pathlib import Path

# Leer AST
ast_file = Path("generated/results/best_algorithm_20251117_143052.txt")
with open(ast_file, 'r') as f:
    ast_content = f.read()

print(ast_content)
```

### Visualizar Convergencia

```python
import json
import matplotlib.pyplot as plt

# Cargar historial
with open("generated/results/history_20251117_143052.json", 'r') as f:
    history = json.load(f)

# Graficar
evals = [h['evaluation'] for h in history]
fitness = [h['best_fitness'] for h in history]

plt.plot(evals, fitness)
plt.xlabel('Evaluaciones')
plt.ylabel('Mejor Fitness')
plt.title('Convergencia del SA')
plt.grid(True)
plt.savefig('generated/convergence.png')
plt.show()
```

---

## üêõ Troubleshooting

### Error: "No se encontraron instancias"

**Causa**: No hay archivos en `datasets/training/`

**Soluci√≥n**:
```powershell
python generate_example_datasets.py
```

### Error: "Campo faltante: n"

**Causa**: Formato de dataset incorrecto

**Soluci√≥n**: Verifica que la primera l√≠nea tenga `n W` y las siguientes `v w`

### Error: "No se ha podido resolver la importaci√≥n numpy"

**Causa**: Dependencias no instaladas

**Soluci√≥n**:
```powershell
pip install -r ../../requirements.txt
```

### Performance lento

**Causas posibles**:
- Demasiadas instancias de entrenamiento
- `max_evaluations` muy alto
- Instancias muy grandes

**Soluci√≥n**: Reduce par√°metros en `config.yaml`

---

## üìà Pr√≥ximos Pasos

1. **Ajustar par√°metros**: Experimenta con diferentes valores de `T0`, `alpha`
2. **M√°s datasets**: A√±ade m√°s instancias variadas
3. **Comparar metaheur√≠sticas**: Prueba GP en lugar de SA
4. **Visualizaci√≥n**: Genera gr√°ficas de convergencia
5. **Benchmarking**: Compara con algoritmos conocidos

---

**√öltima actualizaci√≥n**: 2025-11-17
