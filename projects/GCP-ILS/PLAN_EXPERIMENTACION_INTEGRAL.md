# Plan de ExperimentaciÃ³n Integral - GCP-ILS

**Fecha**: 30 de Diciembre, 2025  
**Proyecto**: GCP-ILS  
**Objetivo**: AnÃ¡lisis exhaustivo del rendimiento del algoritmo ILS

---

## ğŸ“‹ Plan Ejecutivo

### Fases de ExperimentaciÃ³n

```
FASE 1: BENCHMARK BASELINE (15 min)
â”œâ”€ Ejecutar instancias de referencia con parÃ¡metros por defecto
â”œâ”€ Establecer mÃ©tricas base (tiempo, calidad, factibilidad)
â””â”€ Generar tabla de resultados

FASE 2: COMPARATIVA DE OPERADORES (30 min)
â”œâ”€ Variar constructivas (5 alternativas)
â”œâ”€ Variar local search (4 alternativas)
â”œâ”€ Medir impacto en calidad y convergencia
â””â”€ Identificar mejores combinaciones

FASE 3: PARAMETER TUNING (25 min)
â”œâ”€ Variar max_iterations (100, 500, 1000, 2000)
â”œâ”€ Variar perturbation_strength (0.1, 0.2, 0.3, 0.5)
â”œâ”€ Variar restart_threshold (10, 30, 50, 100)
â””â”€ AnÃ¡lisis de sensibilidad

FASE 4: INSTANCIA SCALING (20 min)
â”œâ”€ PequeÃ±as (n < 50): myciel3-5
â”œâ”€ Medianas (50 < n < 500): le450_5a-d
â”œâ”€ Grandes (n > 500): school1, miles*
â””â”€ Analizar escalabilidad

FASE 5: CONVERGENCE ANALYSIS (20 min)
â”œâ”€ Registrar k en cada iteraciÃ³n
â”œâ”€ Graficar convergencia
â”œâ”€ Medir velocidad de convergencia
â””â”€ AnÃ¡lisis de estabilidad

FASE 6: BENCHMARK vs Ã“PTIMOS (15 min)
â”œâ”€ Comparar contra Ã³ptimos conocidos (si estÃ¡n disponibles)
â”œâ”€ Calcular gap para cada instancia
â”œâ”€ Evaluar calidad de soluciones
â””â”€ Generar reporte final
```

**Tiempo Total Estimado**: ~2 horas

---

## ğŸ“Š Estructura de Datos para Resultados

### Tabla Principal de Resultados
```
instance | n | m | constructive | local_search | max_iter | k_found | optimal | gap% | time(s) | feasible | iters_completed
---------|---|---|---|---|---|---|---|---|---|---|---|---
myciel3  | 11| 20| dsatur       | kempe        | 100      | 4       | ?       | ?    | 0.01   | YES      | 100
...
```

### Tabla de Convergencia
```
instance | iteration | k_current | time_at_iter | improvement
---------|-----------|-----------|--------------|-------------
myciel4  | 0         | 5         | 0.0          | initial
myciel4  | 1         | 5         | 0.001        | -
myciel4  | 5         | 5         | 0.005        | -
...
```

### Tabla de Sensibilidad de ParÃ¡metros
```
parameter | value | avg_quality | avg_time | std_dev
----------|-------|-------------|----------|--------
max_iter  | 100   | 5.2         | 0.5s     | 0.3
max_iter  | 500   | 4.8         | 1.2s     | 0.2
max_iter  | 1000  | 4.5         | 2.1s     | 0.1
...
```

---

## ğŸ”§ Scripts a Crear

### 1. `experimentation/experiment_benchmark.py`
```python
"""
Fase 1: Benchmark Baseline
- Ejecutar 15 instancias con parÃ¡metros por defecto
- Medir tiempo, calidad, factibilidad
- Generar tabla de resultados
"""
```

### 2. `experimentation/experiment_operators.py`
```python
"""
Fase 2: Comparativa de Operadores
- 5 constructivas Ã— 4 local search = 20 combinaciones
- Ejecutar sobre 5 instancias pequeÃ±as
- Medir impacto en k y convergencia
"""
```

### 3. `experimentation/experiment_parameters.py`
```python
"""
Fase 3: Parameter Tuning
- max_iterations: [100, 500, 1000, 2000]
- perturbation_strength: [0.1, 0.2, 0.3, 0.5]
- restart_threshold: [10, 30, 50, 100]
- AnÃ¡lisis de sensibilidad 3D
"""
```

### 4. `experimentation/experiment_scaling.py`
```python
"""
Fase 4: Instancia Scaling
- Instancias pequeÃ±as (n<50)
- Instancias medianas (50<n<500)
- Instancias grandes (n>500)
- Analizar crecimiento de tiempo
"""
```

### 5. `experimentation/experiment_convergence.py`
```python
"""
Fase 5: Convergence Analysis
- Registrar k en cada iteraciÃ³n
- Graficar evoluciÃ³n
- Medir velocidad de convergencia
- EstadÃ­sticas de estabilidad
"""
```

### 6. `experimentation/experiment_benchmark_optimal.py`
```python
"""
Fase 6: Benchmark vs Ã“ptimos
- Cargar Ã³ptimos conocidos
- Calcular gaps
- Generar reporte final
"""
```

### 7. `experimentation/run_all_experiments.py`
```python
"""
Master script: Ejecuta todas las fases
- Orquesta las 6 fases
- Recolecta resultados
- Genera reportes integrados
"""
```

---

## ğŸ“ˆ MÃ©tricas a Recopilar

### Por EjecuciÃ³n
- **k_found**: NÃºmero de colores encontrados
- **time_elapsed**: Tiempo total en segundos
- **iterations_completed**: Iteraciones hasta terminar
- **feasible**: Si la soluciÃ³n es vÃ¡lida
- **conflicts**: NÃºmero de conflictos (siempre debe ser 0)
- **improvement_rate**: (k_initial - k_final) / k_initial

### Agregadas
- **avg_quality**: k promedio por instancia
- **std_quality**: DesviaciÃ³n estÃ¡ndar de k
- **avg_time**: Tiempo promedio por instancia
- **convergence_speed**: Iteraciones necesarias para converger
- **robustness**: % de ejecuciones exitosas

### Comparativas
- **gap_to_optimal**: (k_found - optimal) / optimal * 100
- **speedup**: tiempo_baseline / tiempo_variante
- **quality_improvement**: (k_baseline - k_variante) / k_baseline * 100

---

## ğŸ¯ Instancias Seleccionadas

### Benchmark Set (15 instancias variadas)

**PequeÃ±as (n < 50)**:
- myciel3 (11 vÃ©rtices)
- myciel4 (23 vÃ©rtices)
- myciel5 (47 vÃ©rtices)

**Medianas (50 < n < 500)**:
- le450_5a (450 vÃ©rtices)
- le450_5b (450 vÃ©rtices)
- le450_15a (450 vÃ©rtices)

**Grandes (n > 500)**:
- school1 (385 vÃ©rtices)
- anna (138 vÃ©rtices)
- david (87 vÃ©rtices)
- homer (561 vÃ©rtices)
- huck (74 vÃ©rtices)
- jean (80 vÃ©rtices)
- games120 (120 vÃ©rtices)
- miles500 (128 vÃ©rtices)
- queen10_10 (100 vÃ©rtices)

**Total**: 15 instancias cobriendo todas las familias

---

## ğŸ“Š Salidas Esperadas

### Reportes Generados

1. **results/benchmark_baseline.csv**
   - Resultados de fase 1
   - 15 instancias Ã— parÃ¡metros por defecto

2. **results/operators_comparison.csv**
   - Resultados de fase 2
   - 20 combinaciones Ã— 5 instancias

3. **results/parameter_tuning.csv**
   - Resultados de fase 3
   - AnÃ¡lisis de sensibilidad

4. **results/scaling_analysis.csv**
   - Resultados de fase 4
   - RelaciÃ³n n vs tiempo

5. **results/convergence_data.csv**
   - Datos de convergencia
   - k vs iteraciÃ³n para grÃ¡ficos

6. **results/benchmark_optimal.csv**
   - Gaps respecto a Ã³ptimos
   - EvaluaciÃ³n de calidad

7. **results/EXPERIMENT_REPORT.md**
   - Resumen ejecutivo
   - GrÃ¡ficos y anÃ¡lisis
   - Conclusiones

---

## ğŸ¬ EjecuciÃ³n

### Comando Master
```bash
python experimentation/run_all_experiments.py
```

### O por fases
```bash
python experimentation/experiment_benchmark.py
python experimentation/experiment_operators.py
python experimentation/experiment_parameters.py
python experimentation/experiment_scaling.py
python experimentation/experiment_convergence.py
python experimentation/experiment_benchmark_optimal.py
```

---

## ğŸ“ˆ GrÃ¡ficos Esperados

### Fase 2: Comparativa de Operadores
```
GrÃ¡fico de barras: Promedio k por constructor/local_search
- X: Combinaciones de operadores
- Y: k promedio
```

### Fase 3: Parameter Tuning
```
Heatmap 3D: max_iterations vs perturbation_strength vs restart_threshold
- Color: k promedio
```

### Fase 4: Scaling
```
LÃ­nea: TamaÃ±o instancia vs Tiempo
- X: n (vÃ©rtices)
- Y: Tiempo (segundos)
- RegresiÃ³n para estimar complejidad
```

### Fase 5: Convergence
```
LÃ­nea mÃºltiple: IteraciÃ³n vs k
- Una lÃ­nea por instancia
- Mostrar velocidad de convergencia
```

---

## âœ… Checklist de ImplementaciÃ³n

- [ ] Crear estructura `/experimentation/` con 7 scripts
- [ ] Crear `/results/` para almacenar CSVs
- [ ] Implementar recolecciÃ³n de datos uniforme
- [ ] Implementar generaciÃ³n de grÃ¡ficos
- [ ] Implementar reporte final integrado
- [ ] Ejecutar todas las fases
- [ ] Validar resultados
- [ ] Documentar hallazgos

---

## ğŸ“ Salida Final Esperada

```
EXPERIMENT COMPLETE: GCP-ILS Comprehensive Analysis
=====================================================

Phase 1: Benchmark Baseline
  âœ“ 15 instances analyzed
  âœ“ Average k: 5.8
  âœ“ Average time: 1.2s

Phase 2: Operators Comparison
  âœ“ 20 combinations tested
  âœ“ Best: DSATUR + KempeChain (avg k=5.2)
  âœ“ Worst: Random + SwapColors (avg k=6.8)

Phase 3: Parameter Tuning
  âœ“ 64 combinations analyzed
  âœ“ Optimal: max_iter=1000, perturb=0.2, restart=50
  âœ“ Quality improvement: +15%

Phase 4: Scaling Analysis
  âœ“ Complexity: ~O(n^1.5)
  âœ“ Largest instance: 561 verts in 12.3s

Phase 5: Convergence Analysis
  âœ“ Median convergence: 120 iterations
  âœ“ Stability: 98% (consistent results)

Phase 6: Benchmark vs Optimal
  âœ“ Average gap: 12%
  âœ“ Best performance: myciel3 (0% gap)
  âœ“ Worst performance: le450_5a (45% gap)

=====================================================
Reports saved to: results/
Graphs saved to: results/graphs/
```

---

## ğŸ’¡ Decisiones Clave del Plan

1. **Instancias variadas**: Desde muy pequeÃ±as a grandes para ver escalabilidad
2. **Combinaciones completas**: Todos los operadores Ã— instancias para comparativa justa
3. **Parameter tuning sistemÃ¡tico**: AnÃ¡lisis de sensibilidad para encontrar Ã³ptimos
4. **Convergence tracking**: Entender cÃ³mo se comporta el algoritmo
5. **Benchmark vs Ã³ptimos**: Validar que el algoritmo produce buenas soluciones

---

**PrÃ³ximo paso**: Â¿Quieres que implemente todos estos scripts de experimentaciÃ³n?
